---
layout: single
published: true
title:  "Hadoop 에코시스템"
permalink: /data/hadoop-eco-system
categories: Computer Science
date: 2025-06-11 21:20:00
toc: true
toc_sticky: true
header:
  title: "Hadoop 에코시스템"
  teaser: assets/images/cs_th.png
excerpt: "Hadoop 에코시스템에 대해 알아봅니다."
tag:   
  - Hadoop 에코시스템
  - HDFS
  - MapReduce
  - YARN

---

## 빅데이터

데이터의 양이 너무 방대하거나(Volume), 생성 속도가 너무 빠르거나(Velocity), 형태가 너무 다양하여(Variety) 기존의 관계형 데이터베이스 관리 시스템(RDBMS)으로는 처리하기 어려운 데이터를 빅데이터라고 합니다. 이 세 가지 특성을 3V라고 하며, 여기에 데이터의 신뢰성(Veracity)과 가치(Value)를 더해 5V라기도 하고, 정확성(Validity)와 휘발성(volatility)을 더해 7V라기도 합니다.

이러한 빅데이터를 처리하기 위해서는 하둡이나 스파크같은 분산 처리 시스템이 필요합니다. 단일 서버의 한계를 뛰어넘어, 수많은 서버(노드)에 데이터를 분산 저장하고 병렬로 처리함으로써 대규모 데이터 작업을 빠르고 안정적으로 수행할 수 있게 됩니다.


## Hadoop 에코시스템

Hadoop은 대규모 데이터를 분산 저장하고 처리하기 위한 오픈 소스 프레임워크입니다.

Hadoop은 다음과 같이 세 가지로 구성됩니다.

- HDFS: 데이터를 잘게 쪼개서 분산 저장하는 파일 시스템
- MapReduce: 분산된 데이터를 병렬로 처리하는 프로그래밍 모델
- YARN: 클러스터의 자원을 관리하고 다양한 애플리케이션을 실행하는 프레임워크

### HDFS

HDFS는 하둡의 모듈로서 데이터를 잘게 쪼개서 분산 저장하는 파일 시스템입니다.

데이터를 저장하는 방식은 다음과 같습니다. 
1. 데이터를 128M 블록 단위로 잘게 쪼갭니다. 
2. 그걸 여러 컴퓨터(**데이터 노드**) 서버들에 분산시켜서 저장을 합니다. 
3. 혹시 모르니까 각 블록을 기본적으로 세 군데 복제를 해둡니다. 

장점은 복제를 해두니깐 서버 하나가 문제가 생겨도 데이터는 안 날아가는 장점이 있습니다. 

그리고 **네임노드**라는 게 있는데, 지도라고 보면 됩니다. 어떤 데이터 블록들이 어디 저장되어 있는지 정보를 관리하는 역할을 합니다. 즉, 메타데이터를 관리합니다. 또한 데이터에 대한 사용자 접근 권한도 관리하기도 합니다.

<p align="center"><img src="https://github.com/user-attachments/assets/da6e3b72-e614-465d-bdc7-aa6b969ce3b1" width="80%" height="80%"></p>
<p align="right">⤷ HDFS 아키텍처</p>

위에 HDFS 아키텍처에서 빨간색을 보면 Client - Read (읽기)과정이 있는데요. 설명하자면 클라이언트가 파일을 읽으려고 할때 NameNode에 파일의 블록 위치 정보를 요청하면 NameNode는 클라이언트에게 해당 블록을 저장하고 있는 DataNode의 정보를 알려줍니다. 그럼 클라이언트는 제공받은 DataNode 목록 중에서 네트워크적으로 가장 가까운 DataNode를 선택하여 해당 DataNode에게 특정 블록을 요청합니다.
선택된 DataNode는 요청받은 블록을 자신의 로컬 파일 시스템에서 찾아 클라이언트에게 직접 스트림 방식으로 데이터를 전송합니다.

Client - Write (쓰기)는 클라이언트는 NameNode로부터 할당받은 DataNode에 직접 데이터 블록을 스트림 방식으로 전송합니다. 이때 하나의 DataNode에 데이터를 저장 하고 끝나는게 아니라, 동시에 다른 두 번째, 세 번째 DataNode에 데이터를 전달하여 복제(Replication)를 진행합니다.


### MapReduce

HDFS가 데이터를 효율적으로 저장하는 시스템이라는것을 알았으니 이제는 그 저장된 데이터를 효율적으로 "처리"하는 MapReduce에 대해 알아보겠습니다. 

MapReduce는 HDFS에 저장된 **대규모 데이터를 병렬로 처리**하기 위한 프로그래밍 모델입니다.

먼저 쉽게 설명하자면, MapReduce는 "많은 사람들에게 작업을 나눠주고, 그 결과들을 모아서 최종 결과물을 만드는 효율적인 작업 지시 및 취합 방식" 이라고 할 수 있습니다.

MapReduce는 이름에서 알 수 있듯이, Map과 Reduce라는 단계와 중간에 Shuffle & Sort 단계로 구성됩니다.

<p align="center"><img src="https://github.com/user-attachments/assets/196ac2e4-ec55-44a7-b55a-54f6863365e1" width="80%" height="80%"></p>
<p align="right">⤷ MapReduce</p>

- **Map** 단계:  
  입력 데이터를 작은 조각들로 분할하여 각각의 Mapper(매퍼) 작업에 할당합니다. 각 Mapper는 할당된 데이터 조각을 처리하여 (key, value)형태로 변환합니다.  

- **Shuffle & Sort** 단계:  
  Map 단계에서 생성된 중간 (key, value) 쌍들을 Reduce 단계로 보내기 전에, 동일한 key를 가진 value들을 한 곳으로 모아서 정렬합니다.  

- **Reduce** 단계:  
  Shuffle & Sort 단계를 통해 전달받은 value 리스트를 집계, 요약해서 최종 (key, value) 쌍의 결과물을 생성합니다. 


하지만 이 맵리듀스가 처리 중간 결과들을 계속 디스크에다 썼다 지웠다해서 속도가 좀 느립니다. 그래서 Spark를 사용하게 되는데 Spark는 마지막에 설명하겠습니다.

### YARN

아까 알아보았던 MapReduce의 처리 작업이 실제로 어떤 노드에서, 얼마만큼의 자원을 가지고, 언제 실행할지를 결정하고 관리하는 시스템이 필요합니다. 이때 MapReduce가 클러스터 자원을 효율적으로 사용할 수 있도록 "지휘"하는 역할이 YARN입니다.

즉, YARN은 데이터 처리 작업을 위한 **자원 관리와 작업 스케줄링** 프레임워크입니다. 

<p align="center"><img src="https://github.com/user-attachments/assets/ae684e59-077c-4000-a8f1-ac470d2c24fa" width="80%" height="80%"></p>
<p align="right">⤷ YARN 아키텍처</p>

YARN은 세 가지 주요 컴포넌트로 구성됩니다.

- **ResourceManager** (리소스매니저):
  클러스터 전체의 모든 자원(CPU, 메모리)을 파악하고, 여러 애플리케이션(작업)들이 요청하는 자원을 공정하고 효율적으로 배분하는 역할을 합니다.

- **NodeManager** (노드매니저):
  자신이 맡은 노드 안에서 ResourceManager의 지시를 받아 실제 자원(Container)을 만들고, 그 안에서 작업을 실행하며, 노드의 자원 사용량을 ResourceManager에게 보고하는 역할을 합니다.

- **ApplicationMaster** (애플리케이션 마스터):
  하나의 MapReduce 혹은 Spark를 YARN에서 실행되는 각 애플리케이션마다 별도로 생성됩니다. 해당 애플리케이션의 자원 요청부터 실제 태스크 실행, 그리고 작업 진행 상황 모니터링까지 전반적인 책임을 맡습니다.


## Spark

이제는 아까 전에 언급했던 MapReduce의 느린 속도를 보완하는 도구인 Spark에 대해 알아보겠습니다. 

Spark는 대규모 데이터 처리 및 분석을 위한 빠른 클러스터 컴퓨팅 프레임워크입니다. MapReduce가 중간 결과를 디스크에 저장하여 속도 제약이 있던 것과 달리, Spark는 데이터를 메모리에 올려놓는 인메모리 방식으로 처리합니다. 덕분에 반복적인 작업에서 MapReduce보다 빠른 성능을 자랑합니다.

<p align="center"><img src="https://github.com/user-attachments/assets/d76ec83e-b0f5-45dc-b93b-a13e6a7c9f54" width="80%" height="80%"></p>
<p align="right">⤷ MapReduce processing vs Spark processing</p>

또한 MapReduce는 배치 처리만을 하지만, Spark는 배치 처리를 포함하여 스트리밍, 대화형 쿼리, 머신러닝, 그래프 처리 기능을 가지고 있습니다.

<p align="center"><img src="https://github.com/user-attachments/assets/cda45644-d4bd-42c9-b39a-d2e308df07a2" width="80%" height="80%"></p>
<p align="right">⤷ Spark 코어</p>

Spark Core는 Spark 플랫폼의 기초입니다. 메모리 관리, 장애 복구, 스케줄링, 작업 배포 및 모니터링, 스토리지 시스템과의 상호 작용을 담당합니다. Spark Core는 **RDD**라는 추상화를 통해 이런 기능들을 제공하고, Java, Scala, Python, R용으로 구축된 API를 통해 개발자들이 Spark의 분산 처리 기능을 손쉽게 활용할 수 있도록 합니다.

※ RDD는 스파크의 기본 데이터 구조입니다. 분산 변경 불가능한 객체 모음이며 스파크의 모든 작업은 새로운 RDD를 만들거나 존재하는 RDD를 변형하거나 결과 계산을 위해 RDD에서 연산하는 것을 표현하고 있습니다.

##### Spark 아케텍처

<p align="center"><img src="https://github.com/user-attachments/assets/fa44d95f-1f6d-471f-b938-8d1c3e0ad8c5" width="80%" height="80%"></p>
<p align="right">⤷ Spark 아키텍처</p>

- Driver Program (드라이버 프로그램):
  Spark 애플리케이션의 두뇌 역할을 합니다.
  작성한 Spark 코드가 실행되는 곳이며, 전체 작업의 흐름을 지시하고 태스크를 분할하며, 클러스터에 자원을 요청하고 결과를 수집합니다.
- Cluster Manager (클러스터 매니저):
  Spark 애플리케이션에게 클러스터의 자원(CPU, 메모리)을 할당해주는 자원 배분자입니다.
  YARN, Apache Mesos, Kubernetes, Spark 자체의 Standalone(독립형) 모드가 있습니다.
- Executors (익스큐터):
  각 워커 노드(실제 데이터가 있는 서버들)에서 실행되는 실제 일꾼들입니다.
  드라이버가 지시하는 계산 작업을 수행하고, 중간 결과를 저장하거나 데이터를 읽고 쓰는 역할을 합니다.




<br><br>


이미지 출처:  
 · DataBricks  
 · TechVidvan  
 · Apache  
 · moons08  
 · AWS
 · EduinPro