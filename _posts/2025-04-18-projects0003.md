---
layout: single
published: true
title:  "[Projects]모찌케어 - 데이터 분석 및 파이프라인 구축 과정 회고"
permalink: /projects/mochicare-reflecting-on-data-pipeline
categories: projects
date: 2025-04-18 20:15:00
toc: true
toc_sticky: true
header:
  title: "[Projects]모찌케어 - 데이터 분석 및 파이프라인 구축 과정 회고"
  teaser: assets/images/mochicare-data-pipeline-teaser.png
excerpt: "모찌케어 프로젝트 기획과 개발 타당성을 검증하기 위해 데이터 분석 파이프라인 구축 과정을 기록합니다"
tag:   
  - project
  - data pipeline
  - data analysis
  - glue
  - athena
  - quicksight
  - s3
---

![babycareai-mochcare](https://github.com/user-attachments/assets/5150a8cd-f3dd-4105-8ceb-d5d656bd2024)

AI 기반 영유아 피부 질환 진단 서비스 '모찌케어' 프로젝트 초기 단계에서 기획과 개발 타당성을 검증하기 위해 관련 데이터를 분석하려 했다. 이를 위해서 데이터 수집하고 처리하는 등 **데이터 분석 파이프라인 구축 과정**을 기록하려고 한다.

## 프로젝트 배경

‘모찌케어’는 영유아를 양육하는 부모나 양육자가 아기의 피부 사진을 찍고 증상을 입력하면 AI 기술을 활용하여 피부 질환을 진단해주는 서비스이다. 개발 전 단계에서 실제 사용자들의 니즈와 딥러닝 모델 클래스 선정 등 여러가지 정보들이 필요했기 때문에, 두 가지 방식으로 데이터를 수집했다:

1. 직접 설문조사 진행 (101명)
2. 네이버 카페 "맘스홀릭베이비"의 "아기 건강 질문방" 게시판에서 1년간 올라온 게시글 스크래핑 (약 65,600개)

## 데이터 파이프라인 아키텍처 설계

수집된 데이터의 특성에 따라 처리 방식을 달리했다. ‘설문조사‘ 데이터는 규모가 작고 구조화되어 있어 로컬 환경에서 간단히 분석했지만, ‘웹 스크래핑‘으로 수집한 대량의 비정형 데이터는 AWS 클라우드 서비스를 활용한 데이터 파이프라인을 구축했다.

처음에는 파이프라인을 구축하지 않고 코드 기반으로 진행했으나, 한국어 형태소를 다루면서 분석 로직이 점점 복잡해지고 관리가 어려워졌다. 또한 빈도와 TF-IDF의 분석 결과가 크게 다르지 않다는 점(TF와 TF-IDF 결과의 유사점)을 알게되었고, 주요 단어들이 모든 문서에 고르게 분포되어 있다고 판단했다. 이에 따라, 데이터 마트를 구축하고 SQL을 활용한 분석 방식이 보다 효율적일 것으로 보았다.

### AWS 클라우드 기반 데이터 파이프라인 구성

![image.png](https://github.com/user-attachments/assets/7422a3bb-afb4-44dc-a27a-e0b44c208d75)

흐름은 다음과 같다.

1. **데이터 수집 및 저장**: 웹 스크래핑을 통해 수집된 원시 데이터를 AWS S3의 `/raw-data` 버킷에 저장
2. **데이터 카탈로그화**: AWS Glue Crawler를 사용하여 원시 데이터를 스캔하고 데이터 카탈로그 생성
3. **ETL 작업**: AWS Glue ETL Job을 통해 다음과 같은 정제 작업 수행
    - 날짜 형식 통일
    - 이모지/특수문자 제거
    - 중복 공백 제거
    - 제목과 내용 컬럼 통합
4. **정제 데이터 저장**: 정제된 데이터를 S3의 `/cleansed-data` 버킷에 저장
5. **로컬 환경 텍스트 처리**:
    - 형태소 분석 및 토큰 추출
    - 불용어 제거
    - 키워드 프레임 여부에 따른 그룹화
    - TF-IDF 분석 수행
    - 후속 분석용 데이터 테이블 구축
6. **토큰화된 데이터 저장**: 처리 결과를 다시 S3의 `/tokend-data` 버킷에 저장
7. **쿼리 및 시각화**:
    - AWS Athena를 활용해 SQL 쿼리로 데이터 분석
    - AWS QuickSight로 결과 시각화 및 인사이트 도출

### 데이터 마트 스키마 설계

분석을 위해 다음과 같은 스키마로 데이터 마트를 구성했다:

![image.png](https://github.com/user-attachments/assets/68d42af6-ea55-4c89-8fe9-42096c70b81b)

이때 차원테이블(posts_dim) 같은 경우 비정규화 테이블이다. 만약 운영 중인 서버의 데이터베이스였다면, 작성자(author) 정보를 별도의 author 테이블로 분리하는 등 정규화를 했겠지만, 해당 스키마는 분석을 위한 Data Mart이므로, 조회할 때 별도 테이블 조인 없이 한번에 가져오도록 하였다. 

### **고도화 필요**

- 더 정확한 분석을 위해 해당 네이버 카페의 글을 더 스크래핑하고 분석도 자주 하려고 했기 때문에 데이터 파이프라인을 구축한 이유도 있었다. 하지만 클라우드 환경에서 한국어 처리가 쉽지 않았고(또한 Glue ETL 비용 부담도 있었다.) 결국 중간에 로컬에서 처리를 진행했다. 완전히 클라우드로 통합한다면 자동화 수준도 높일 수 있을 것이다
- MySQL의 인덱스처럼, Athena도 파티션 관련 기능(프로젝션, 인덱스, 필터링)을 적용한다면 쿼리 성능을 높이고 비용을 줄일 수 있을 것이다.

<br>
GitHub Repository: <https://github.com/BabyCareAI> 👈